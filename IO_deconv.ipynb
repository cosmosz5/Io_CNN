{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_0vrC5BYAX7",
        "outputId": "53511d27-31d2-4701-e000-3a322a902fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import astropy.io.fits as pyfits\n",
        "from torchsummary import summary\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import astropy.io.fits as pyfits\n",
        "from torchsummary import summary\n",
        "import argparse\n",
        "import pdb\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Atanh(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Atanh, self).__init__()\n",
        "        self._amp = nn.Parameter(torch.randn(1))\n",
        "        self._slope = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._amp * ((torch.exp(2 * self._slope * x) - 1) / (torch.exp(2 * self._slope * x) + 1))\n"
      ],
      "metadata": {
        "id": "4_C-zukYYubP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AReLU, self).__init__()\n",
        "        self._const = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.maximum(self._const * x, x)"
      ],
      "metadata": {
        "id": "vLFR1DNSYzbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AReLU2(nn.Module):\n",
        "    def __init__(self,):\n",
        "        \"\"\"\n",
        "        Trainable activation function\n",
        "\n",
        "        Args:\n",
        "            init_const (float): Initial value for the trainable constant\n",
        "        \"\"\"\n",
        "        super(AReLU2, self).__init__()\n",
        "\n",
        "        # Create a trainable parameter\n",
        "        # Uses torch.nn.Parameter to make it part of the model's parameters\n",
        "        self._const = nn.Parameter(torch.tensor(torch.randn(1), dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass with trainable activation\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Activated tensor\n",
        "        \"\"\"\n",
        "        return torch.maximum(self._const * x, x)\n"
      ],
      "metadata": {
        "id": "FV9CBlRRY1d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Automap(nn.Module):\n",
        "    def __init__(self, input_shape=(45*45)):\n",
        "        super(Automap, self).__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(45*45, 6*6*256, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Unflatten(1, (256, 6, 6)),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=2, bias=False),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Conv2d(32, 1, kernel_size=4, stride=1, padding=1, bias=False),\n",
        "            AReLU2()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        aa = self.model(x)\n",
        "        return aa"
      ],
      "metadata": {
        "id": "lLrqq5FnY9F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[2:4]\n",
        "    image = torch.zeros((height*shape[0], width*shape[1]))\n",
        "\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = torch.from_numpy(img[0]).float()\n",
        "\n",
        "    return image.numpy()"
      ],
      "metadata": {
        "id": "ZiY8AhtnY-RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(batch_size=128, epochs=200):\n",
        "    # Load data\n",
        "\n",
        "    load_data = np.load('/content/drive/MyDrive/NN_deconv/io_outputs_10_2025.npz')\n",
        "    train_images = load_data['cube']\n",
        "    X_train = train_images.reshape(1, 45, 45, 30000)\n",
        "    X_train = np.swapaxes(X_train, 3, 2)\n",
        "    X_train = np.swapaxes(X_train, 2, 1)\n",
        "    X_train = np.swapaxes(X_train, 1, 0)\n",
        "\n",
        "    #pyfits.writeto('test.fits', X_train[0,0,:,:], overwrite=True)\n",
        "    #pdb.set_trace()\n",
        "\n",
        "    load_oidata = np.load('/content/drive/MyDrive/NN_deconv/io_models_10_2025.npz')\n",
        "    train_oidata = load_oidata['cube'].T\n",
        "\n",
        "    TMP = Automap()\n",
        "    summary(TMP, (45*45,), device = 'cpu')\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    # Convert to torch tensors\n",
        "    X_train_tensor = torch.from_numpy(X_train).float()\n",
        "    train_oidata_tensor = torch.from_numpy(train_oidata).float()\n",
        "\n",
        "    # Setup model, loss, and optimizer\n",
        "    model = Automap().to('cuda')\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.00009)\n",
        "\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    fig2, ax11 = plt.subplots(1, 1, figsize=(9, 6))\n",
        "    metrics = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_losses = []\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "\n",
        "\n",
        "        for index in range(int(X_train.shape[0] / batch_size)):\n",
        "            # Prepare batch\n",
        "            image_batch = X_train_tensor[index * batch_size:(index + 1) * batch_size] ## Deconvolved ims\n",
        "            oidata_batch = train_oidata_tensor[index * batch_size:(index + 1) * batch_size] ### Convolved ims\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(oidata_batch.to('cuda')).to('cuda')\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, image_batch.to('cuda'))\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "            # Periodic image generation and saving\n",
        "            if index % 50 == 0:\n",
        "                with torch.no_grad():\n",
        "                    generated_images = model(oidata_batch.to('cuda')).to('cuda')\n",
        "                    image = combine_images(generated_images.cpu().numpy())\n",
        "\n",
        "                    fig, ax1 = plt.subplots(1,1)\n",
        "                    ax1.imshow(image, cmap='jet', origin='lower')\n",
        "                    fig.savefig(f\"/content/drive/MyDrive/NN_deconv/deconv_10nn/{epoch}_Deconv_{index}.png\")\n",
        "                    pyfits.writeto(f\"/content/drive/MyDrive/NN_deconv/deconv_10nn/{epoch}_Deconv_{index}.fits\", image, overwrite=True)\n",
        "                    plt.close(fig)\n",
        "\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        metrics.append(mean_loss)\n",
        "\n",
        "        ax11.errorbar(epoch, mean_loss, yerr=np.std(epoch_losses), fmt='o', color='red')\n",
        "        ax11.set_xlabel('Epoch')\n",
        "        ax11.set_ylabel('Model MSE')\n",
        "        fig2.savefig('/content/drive/MyDrive/NN_deconv/losses80_Deconv_10_2500.png', bbox_inches='tight')\n",
        "        plt.close(fig2)\n",
        "\n",
        "        # Save model periodically\n",
        "        if epoch % 50 == 0:\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/NN_deconv/deconv_10nn/model_Deconv_{epoch}.pth')\n",
        "\n",
        "    # Save final model and metrics\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/NN_deconv/model_Deconv_10nn_final.pth')\n",
        "    np.savez('/content/drive/MyDrive/NN_deconv/metrics_Deconv_10nn_2500.npz', metrics=metrics)\n"
      ],
      "metadata": {
        "id": "cZVGbS4sZAra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(oifilename):\n",
        "    # Load data\n",
        "    DATA = np.load(oifilename)\n",
        "    DATA = DATA['cube'].astype(np.float32) #.T\n",
        "    #pdb.set_trace()\n",
        "    # Setup model\n",
        "    model = Automap().to('cuda')\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/NN_deconv/model_Deconv_10_final.pth'))\n",
        "    model.eval()\n",
        "\n",
        "    # Convert data to tensor\n",
        "    DATA_tensor = torch.from_numpy(DATA)\n",
        "\n",
        "    # Generate images\n",
        "    with torch.no_grad():\n",
        "        generated_image = model(DATA_tensor.to('cuda'))\n",
        "        generated_images = generated_image.squeeze().cpu().numpy()\n",
        "\n",
        "    # Save generated images\n",
        "    pyfits.writeto('/content/drive/MyDrive/NN_deconv/predicted_images_10_4.fits', generated_images, overwrite=True)\n",
        "    return 0"
      ],
      "metadata": {
        "id": "7l2JbXa3aAel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--mode\", type=str)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
        "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
        "    parser.add_argument(\"--epoch\", type=int, default=10)\n",
        "    parser.add_argument(\"--filename\", type=str)\n",
        "    parser.set_defaults(nice=False)\n",
        "    args = parser.parse_args()\n",
        "    return args"
      ],
      "metadata": {
        "id": "PHiFmTHxaBT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train(batch_size=2048, epochs=2500)\n",
        "\n",
        "    #generate(oifilename='/content/drive/MyDrive/NN_deconv/n_cube_2025_4.npz')\n",
        "\n",
        "\n",
        "    #args = get_args()\n",
        "    #if args.mode == \"train\":\n",
        "    #    train(batch_size=args.batch_size, epochs=args.epoch)\n",
        "    #elif args.mode == \"generate\":\n",
        "    #    generate(oifilename=args.filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgfPSYmtaEux",
        "outputId": "1acc81af-7dc7-47e4-9aeb-ec651738942f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-2338429440.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self._const = nn.Parameter(torch.tensor(torch.randn(1), dtype=torch.float32))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 9216]      18,662,400\n",
            "             PReLU-2                 [-1, 9216]               1\n",
            "         Unflatten-3            [-1, 256, 6, 6]               0\n",
            "   ConvTranspose2d-4          [-1, 128, 12, 12]         524,288\n",
            "             PReLU-5          [-1, 128, 12, 12]               1\n",
            "           Dropout-6          [-1, 128, 12, 12]               0\n",
            "   ConvTranspose2d-7           [-1, 64, 24, 24]         131,072\n",
            "             PReLU-8           [-1, 64, 24, 24]               1\n",
            "           Dropout-9           [-1, 64, 24, 24]               0\n",
            "  ConvTranspose2d-10           [-1, 32, 46, 46]          32,768\n",
            "            PReLU-11           [-1, 32, 46, 46]               1\n",
            "          Dropout-12           [-1, 32, 46, 46]               0\n",
            "           Conv2d-13            [-1, 1, 45, 45]             512\n",
            "           AReLU2-14            [-1, 1, 45, 45]               0\n",
            "================================================================\n",
            "Total params: 19,351,044\n",
            "Trainable params: 19,351,044\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.06\n",
            "Params size (MB): 73.82\n",
            "Estimated Total Size (MB): 76.88\n",
            "----------------------------------------------------------------\n",
            "Epoch: 0\n",
            "Epoch: 1\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Epoch: 5\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "Epoch: 11\n",
            "Epoch: 12\n",
            "Epoch: 13\n",
            "Epoch: 14\n",
            "Epoch: 15\n",
            "Epoch: 16\n",
            "Epoch: 17\n",
            "Epoch: 18\n",
            "Epoch: 19\n",
            "Epoch: 20\n",
            "Epoch: 21\n",
            "Epoch: 22\n",
            "Epoch: 23\n",
            "Epoch: 24\n",
            "Epoch: 25\n",
            "Epoch: 26\n",
            "Epoch: 27\n",
            "Epoch: 28\n",
            "Epoch: 29\n",
            "Epoch: 30\n",
            "Epoch: 31\n",
            "Epoch: 32\n",
            "Epoch: 33\n",
            "Epoch: 34\n",
            "Epoch: 35\n",
            "Epoch: 36\n",
            "Epoch: 37\n",
            "Epoch: 38\n",
            "Epoch: 39\n",
            "Epoch: 40\n",
            "Epoch: 41\n",
            "Epoch: 42\n",
            "Epoch: 43\n",
            "Epoch: 44\n",
            "Epoch: 45\n",
            "Epoch: 46\n",
            "Epoch: 47\n",
            "Epoch: 48\n",
            "Epoch: 49\n",
            "Epoch: 50\n",
            "Epoch: 51\n",
            "Epoch: 52\n",
            "Epoch: 53\n",
            "Epoch: 54\n",
            "Epoch: 55\n",
            "Epoch: 56\n",
            "Epoch: 57\n",
            "Epoch: 58\n",
            "Epoch: 59\n",
            "Epoch: 60\n",
            "Epoch: 61\n",
            "Epoch: 62\n",
            "Epoch: 63\n",
            "Epoch: 64\n",
            "Epoch: 65\n",
            "Epoch: 66\n",
            "Epoch: 67\n",
            "Epoch: 68\n",
            "Epoch: 69\n",
            "Epoch: 70\n",
            "Epoch: 71\n",
            "Epoch: 72\n",
            "Epoch: 73\n",
            "Epoch: 74\n",
            "Epoch: 75\n",
            "Epoch: 76\n",
            "Epoch: 77\n",
            "Epoch: 78\n",
            "Epoch: 79\n",
            "Epoch: 80\n",
            "Epoch: 81\n",
            "Epoch: 82\n",
            "Epoch: 83\n",
            "Epoch: 84\n",
            "Epoch: 85\n",
            "Epoch: 86\n",
            "Epoch: 87\n",
            "Epoch: 88\n",
            "Epoch: 89\n",
            "Epoch: 90\n",
            "Epoch: 91\n",
            "Epoch: 92\n",
            "Epoch: 93\n",
            "Epoch: 94\n",
            "Epoch: 95\n",
            "Epoch: 96\n",
            "Epoch: 97\n",
            "Epoch: 98\n",
            "Epoch: 99\n",
            "Epoch: 100\n",
            "Epoch: 101\n",
            "Epoch: 102\n",
            "Epoch: 103\n",
            "Epoch: 104\n",
            "Epoch: 105\n",
            "Epoch: 106\n",
            "Epoch: 107\n",
            "Epoch: 108\n",
            "Epoch: 109\n",
            "Epoch: 110\n",
            "Epoch: 111\n",
            "Epoch: 112\n",
            "Epoch: 113\n",
            "Epoch: 114\n",
            "Epoch: 115\n",
            "Epoch: 116\n",
            "Epoch: 117\n",
            "Epoch: 118\n",
            "Epoch: 119\n",
            "Epoch: 120\n",
            "Epoch: 121\n",
            "Epoch: 122\n",
            "Epoch: 123\n",
            "Epoch: 124\n",
            "Epoch: 125\n",
            "Epoch: 126\n",
            "Epoch: 127\n",
            "Epoch: 128\n",
            "Epoch: 129\n",
            "Epoch: 130\n",
            "Epoch: 131\n",
            "Epoch: 132\n",
            "Epoch: 133\n",
            "Epoch: 134\n",
            "Epoch: 135\n",
            "Epoch: 136\n",
            "Epoch: 137\n",
            "Epoch: 138\n",
            "Epoch: 139\n",
            "Epoch: 140\n",
            "Epoch: 141\n",
            "Epoch: 142\n",
            "Epoch: 143\n",
            "Epoch: 144\n",
            "Epoch: 145\n",
            "Epoch: 146\n",
            "Epoch: 147\n",
            "Epoch: 148\n",
            "Epoch: 149\n",
            "Epoch: 150\n",
            "Epoch: 151\n",
            "Epoch: 152\n",
            "Epoch: 153\n",
            "Epoch: 154\n",
            "Epoch: 155\n",
            "Epoch: 156\n",
            "Epoch: 157\n",
            "Epoch: 158\n",
            "Epoch: 159\n",
            "Epoch: 160\n",
            "Epoch: 161\n",
            "Epoch: 162\n",
            "Epoch: 163\n",
            "Epoch: 164\n",
            "Epoch: 165\n",
            "Epoch: 166\n",
            "Epoch: 167\n",
            "Epoch: 168\n",
            "Epoch: 169\n",
            "Epoch: 170\n",
            "Epoch: 171\n",
            "Epoch: 172\n",
            "Epoch: 173\n",
            "Epoch: 174\n",
            "Epoch: 175\n",
            "Epoch: 176\n",
            "Epoch: 177\n",
            "Epoch: 178\n",
            "Epoch: 179\n",
            "Epoch: 180\n",
            "Epoch: 181\n",
            "Epoch: 182\n",
            "Epoch: 183\n",
            "Epoch: 184\n",
            "Epoch: 185\n",
            "Epoch: 186\n",
            "Epoch: 187\n",
            "Epoch: 188\n",
            "Epoch: 189\n",
            "Epoch: 190\n",
            "Epoch: 191\n",
            "Epoch: 192\n",
            "Epoch: 193\n",
            "Epoch: 194\n",
            "Epoch: 195\n",
            "Epoch: 196\n",
            "Epoch: 197\n",
            "Epoch: 198\n",
            "Epoch: 199\n",
            "Epoch: 200\n",
            "Epoch: 201\n",
            "Epoch: 202\n",
            "Epoch: 203\n",
            "Epoch: 204\n",
            "Epoch: 205\n",
            "Epoch: 206\n",
            "Epoch: 207\n",
            "Epoch: 208\n",
            "Epoch: 209\n",
            "Epoch: 210\n",
            "Epoch: 211\n",
            "Epoch: 212\n",
            "Epoch: 213\n",
            "Epoch: 214\n",
            "Epoch: 215\n",
            "Epoch: 216\n",
            "Epoch: 217\n",
            "Epoch: 218\n",
            "Epoch: 219\n",
            "Epoch: 220\n",
            "Epoch: 221\n",
            "Epoch: 222\n",
            "Epoch: 223\n",
            "Epoch: 224\n",
            "Epoch: 225\n",
            "Epoch: 226\n",
            "Epoch: 227\n",
            "Epoch: 228\n",
            "Epoch: 229\n",
            "Epoch: 230\n",
            "Epoch: 231\n",
            "Epoch: 232\n",
            "Epoch: 233\n",
            "Epoch: 234\n",
            "Epoch: 235\n",
            "Epoch: 236\n",
            "Epoch: 237\n",
            "Epoch: 238\n",
            "Epoch: 239\n",
            "Epoch: 240\n",
            "Epoch: 241\n",
            "Epoch: 242\n",
            "Epoch: 243\n",
            "Epoch: 244\n",
            "Epoch: 245\n",
            "Epoch: 246\n",
            "Epoch: 247\n",
            "Epoch: 248\n",
            "Epoch: 249\n",
            "Epoch: 250\n",
            "Epoch: 251\n",
            "Epoch: 252\n",
            "Epoch: 253\n",
            "Epoch: 254\n",
            "Epoch: 255\n",
            "Epoch: 256\n",
            "Epoch: 257\n",
            "Epoch: 258\n",
            "Epoch: 259\n",
            "Epoch: 260\n",
            "Epoch: 261\n",
            "Epoch: 262\n",
            "Epoch: 263\n",
            "Epoch: 264\n",
            "Epoch: 265\n",
            "Epoch: 266\n",
            "Epoch: 267\n",
            "Epoch: 268\n",
            "Epoch: 269\n",
            "Epoch: 270\n",
            "Epoch: 271\n",
            "Epoch: 272\n",
            "Epoch: 273\n",
            "Epoch: 274\n",
            "Epoch: 275\n",
            "Epoch: 276\n",
            "Epoch: 277\n",
            "Epoch: 278\n",
            "Epoch: 279\n",
            "Epoch: 280\n",
            "Epoch: 281\n",
            "Epoch: 282\n",
            "Epoch: 283\n",
            "Epoch: 284\n",
            "Epoch: 285\n",
            "Epoch: 286\n",
            "Epoch: 287\n",
            "Epoch: 288\n",
            "Epoch: 289\n",
            "Epoch: 290\n",
            "Epoch: 291\n",
            "Epoch: 292\n",
            "Epoch: 293\n",
            "Epoch: 294\n",
            "Epoch: 295\n",
            "Epoch: 296\n",
            "Epoch: 297\n",
            "Epoch: 298\n",
            "Epoch: 299\n",
            "Epoch: 300\n",
            "Epoch: 301\n",
            "Epoch: 302\n",
            "Epoch: 303\n",
            "Epoch: 304\n",
            "Epoch: 305\n",
            "Epoch: 306\n",
            "Epoch: 307\n",
            "Epoch: 308\n",
            "Epoch: 309\n",
            "Epoch: 310\n",
            "Epoch: 311\n",
            "Epoch: 312\n",
            "Epoch: 313\n",
            "Epoch: 314\n",
            "Epoch: 315\n",
            "Epoch: 316\n",
            "Epoch: 317\n",
            "Epoch: 318\n",
            "Epoch: 319\n",
            "Epoch: 320\n",
            "Epoch: 321\n",
            "Epoch: 322\n",
            "Epoch: 323\n",
            "Epoch: 324\n",
            "Epoch: 325\n",
            "Epoch: 326\n",
            "Epoch: 327\n",
            "Epoch: 328\n",
            "Epoch: 329\n",
            "Epoch: 330\n",
            "Epoch: 331\n",
            "Epoch: 332\n",
            "Epoch: 333\n",
            "Epoch: 334\n",
            "Epoch: 335\n",
            "Epoch: 336\n",
            "Epoch: 337\n",
            "Epoch: 338\n",
            "Epoch: 339\n",
            "Epoch: 340\n",
            "Epoch: 341\n",
            "Epoch: 342\n",
            "Epoch: 343\n",
            "Epoch: 344\n",
            "Epoch: 345\n",
            "Epoch: 346\n",
            "Epoch: 347\n",
            "Epoch: 348\n",
            "Epoch: 349\n",
            "Epoch: 350\n",
            "Epoch: 351\n",
            "Epoch: 352\n",
            "Epoch: 353\n",
            "Epoch: 354\n",
            "Epoch: 355\n",
            "Epoch: 356\n",
            "Epoch: 357\n",
            "Epoch: 358\n",
            "Epoch: 359\n",
            "Epoch: 360\n",
            "Epoch: 361\n",
            "Epoch: 362\n",
            "Epoch: 363\n",
            "Epoch: 364\n",
            "Epoch: 365\n",
            "Epoch: 366\n",
            "Epoch: 367\n",
            "Epoch: 368\n",
            "Epoch: 369\n",
            "Epoch: 370\n",
            "Epoch: 371\n",
            "Epoch: 372\n",
            "Epoch: 373\n",
            "Epoch: 374\n",
            "Epoch: 375\n",
            "Epoch: 376\n",
            "Epoch: 377\n",
            "Epoch: 378\n",
            "Epoch: 379\n",
            "Epoch: 380\n",
            "Epoch: 381\n",
            "Epoch: 382\n",
            "Epoch: 383\n",
            "Epoch: 384\n",
            "Epoch: 385\n",
            "Epoch: 386\n",
            "Epoch: 387\n",
            "Epoch: 388\n",
            "Epoch: 389\n",
            "Epoch: 390\n",
            "Epoch: 391\n",
            "Epoch: 392\n",
            "Epoch: 393\n",
            "Epoch: 394\n",
            "Epoch: 395\n",
            "Epoch: 396\n",
            "Epoch: 397\n",
            "Epoch: 398\n",
            "Epoch: 399\n",
            "Epoch: 400\n",
            "Epoch: 401\n",
            "Epoch: 402\n",
            "Epoch: 403\n",
            "Epoch: 404\n",
            "Epoch: 405\n",
            "Epoch: 406\n",
            "Epoch: 407\n",
            "Epoch: 408\n",
            "Epoch: 409\n",
            "Epoch: 410\n",
            "Epoch: 411\n",
            "Epoch: 412\n",
            "Epoch: 413\n",
            "Epoch: 414\n",
            "Epoch: 415\n",
            "Epoch: 416\n",
            "Epoch: 417\n",
            "Epoch: 418\n",
            "Epoch: 419\n",
            "Epoch: 420\n",
            "Epoch: 421\n",
            "Epoch: 422\n",
            "Epoch: 423\n",
            "Epoch: 424\n",
            "Epoch: 425\n",
            "Epoch: 426\n",
            "Epoch: 427\n",
            "Epoch: 428\n",
            "Epoch: 429\n",
            "Epoch: 430\n",
            "Epoch: 431\n",
            "Epoch: 432\n",
            "Epoch: 433\n",
            "Epoch: 434\n",
            "Epoch: 435\n",
            "Epoch: 436\n",
            "Epoch: 437\n",
            "Epoch: 438\n",
            "Epoch: 439\n",
            "Epoch: 440\n",
            "Epoch: 441\n",
            "Epoch: 442\n",
            "Epoch: 443\n",
            "Epoch: 444\n",
            "Epoch: 445\n",
            "Epoch: 446\n",
            "Epoch: 447\n",
            "Epoch: 448\n",
            "Epoch: 449\n",
            "Epoch: 450\n",
            "Epoch: 451\n",
            "Epoch: 452\n",
            "Epoch: 453\n",
            "Epoch: 454\n",
            "Epoch: 455\n",
            "Epoch: 456\n",
            "Epoch: 457\n",
            "Epoch: 458\n",
            "Epoch: 459\n",
            "Epoch: 460\n",
            "Epoch: 461\n",
            "Epoch: 462\n",
            "Epoch: 463\n",
            "Epoch: 464\n",
            "Epoch: 465\n",
            "Epoch: 466\n",
            "Epoch: 467\n",
            "Epoch: 468\n",
            "Epoch: 469\n",
            "Epoch: 470\n",
            "Epoch: 471\n",
            "Epoch: 472\n",
            "Epoch: 473\n",
            "Epoch: 474\n",
            "Epoch: 475\n",
            "Epoch: 476\n",
            "Epoch: 477\n",
            "Epoch: 478\n",
            "Epoch: 479\n",
            "Epoch: 480\n",
            "Epoch: 481\n",
            "Epoch: 482\n",
            "Epoch: 483\n",
            "Epoch: 484\n",
            "Epoch: 485\n",
            "Epoch: 486\n",
            "Epoch: 487\n",
            "Epoch: 488\n",
            "Epoch: 489\n",
            "Epoch: 490\n",
            "Epoch: 491\n",
            "Epoch: 492\n",
            "Epoch: 493\n",
            "Epoch: 494\n",
            "Epoch: 495\n",
            "Epoch: 496\n",
            "Epoch: 497\n",
            "Epoch: 498\n",
            "Epoch: 499\n",
            "Epoch: 500\n",
            "Epoch: 501\n",
            "Epoch: 502\n",
            "Epoch: 503\n",
            "Epoch: 504\n",
            "Epoch: 505\n",
            "Epoch: 506\n",
            "Epoch: 507\n",
            "Epoch: 508\n",
            "Epoch: 509\n",
            "Epoch: 510\n",
            "Epoch: 511\n",
            "Epoch: 512\n",
            "Epoch: 513\n",
            "Epoch: 514\n",
            "Epoch: 515\n",
            "Epoch: 516\n",
            "Epoch: 517\n",
            "Epoch: 518\n",
            "Epoch: 519\n",
            "Epoch: 520\n",
            "Epoch: 521\n",
            "Epoch: 522\n",
            "Epoch: 523\n",
            "Epoch: 524\n",
            "Epoch: 525\n",
            "Epoch: 526\n",
            "Epoch: 527\n",
            "Epoch: 528\n",
            "Epoch: 529\n",
            "Epoch: 530\n",
            "Epoch: 531\n",
            "Epoch: 532\n",
            "Epoch: 533\n",
            "Epoch: 534\n",
            "Epoch: 535\n",
            "Epoch: 536\n",
            "Epoch: 537\n",
            "Epoch: 538\n",
            "Epoch: 539\n",
            "Epoch: 540\n",
            "Epoch: 541\n",
            "Epoch: 542\n",
            "Epoch: 543\n",
            "Epoch: 544\n",
            "Epoch: 545\n",
            "Epoch: 546\n",
            "Epoch: 547\n",
            "Epoch: 548\n",
            "Epoch: 549\n",
            "Epoch: 550\n",
            "Epoch: 551\n",
            "Epoch: 552\n",
            "Epoch: 553\n",
            "Epoch: 554\n",
            "Epoch: 555\n",
            "Epoch: 556\n",
            "Epoch: 557\n",
            "Epoch: 558\n",
            "Epoch: 559\n",
            "Epoch: 560\n",
            "Epoch: 561\n",
            "Epoch: 562\n",
            "Epoch: 563\n",
            "Epoch: 564\n",
            "Epoch: 565\n",
            "Epoch: 566\n",
            "Epoch: 567\n",
            "Epoch: 568\n",
            "Epoch: 569\n",
            "Epoch: 570\n",
            "Epoch: 571\n",
            "Epoch: 572\n",
            "Epoch: 573\n",
            "Epoch: 574\n",
            "Epoch: 575\n",
            "Epoch: 576\n",
            "Epoch: 577\n",
            "Epoch: 578\n",
            "Epoch: 579\n",
            "Epoch: 580\n",
            "Epoch: 581\n",
            "Epoch: 582\n",
            "Epoch: 583\n",
            "Epoch: 584\n",
            "Epoch: 585\n",
            "Epoch: 586\n",
            "Epoch: 587\n",
            "Epoch: 588\n",
            "Epoch: 589\n",
            "Epoch: 590\n",
            "Epoch: 591\n",
            "Epoch: 592\n",
            "Epoch: 593\n",
            "Epoch: 594\n",
            "Epoch: 595\n",
            "Epoch: 596\n",
            "Epoch: 597\n",
            "Epoch: 598\n",
            "Epoch: 599\n",
            "Epoch: 600\n",
            "Epoch: 601\n",
            "Epoch: 602\n",
            "Epoch: 603\n",
            "Epoch: 604\n",
            "Epoch: 605\n",
            "Epoch: 606\n",
            "Epoch: 607\n",
            "Epoch: 608\n",
            "Epoch: 609\n",
            "Epoch: 610\n",
            "Epoch: 611\n",
            "Epoch: 612\n",
            "Epoch: 613\n",
            "Epoch: 614\n",
            "Epoch: 615\n",
            "Epoch: 616\n",
            "Epoch: 617\n",
            "Epoch: 618\n",
            "Epoch: 619\n",
            "Epoch: 620\n",
            "Epoch: 621\n",
            "Epoch: 622\n",
            "Epoch: 623\n",
            "Epoch: 624\n",
            "Epoch: 625\n",
            "Epoch: 626\n",
            "Epoch: 627\n",
            "Epoch: 628\n",
            "Epoch: 629\n",
            "Epoch: 630\n",
            "Epoch: 631\n",
            "Epoch: 632\n",
            "Epoch: 633\n",
            "Epoch: 634\n",
            "Epoch: 635\n",
            "Epoch: 636\n",
            "Epoch: 637\n",
            "Epoch: 638\n",
            "Epoch: 639\n",
            "Epoch: 640\n",
            "Epoch: 641\n",
            "Epoch: 642\n",
            "Epoch: 643\n",
            "Epoch: 644\n",
            "Epoch: 645\n",
            "Epoch: 646\n",
            "Epoch: 647\n",
            "Epoch: 648\n",
            "Epoch: 649\n",
            "Epoch: 650\n",
            "Epoch: 651\n",
            "Epoch: 652\n",
            "Epoch: 653\n",
            "Epoch: 654\n",
            "Epoch: 655\n",
            "Epoch: 656\n",
            "Epoch: 657\n",
            "Epoch: 658\n",
            "Epoch: 659\n",
            "Epoch: 660\n",
            "Epoch: 661\n",
            "Epoch: 662\n",
            "Epoch: 663\n",
            "Epoch: 664\n",
            "Epoch: 665\n",
            "Epoch: 666\n",
            "Epoch: 667\n",
            "Epoch: 668\n",
            "Epoch: 669\n",
            "Epoch: 670\n",
            "Epoch: 671\n",
            "Epoch: 672\n",
            "Epoch: 673\n",
            "Epoch: 674\n",
            "Epoch: 675\n",
            "Epoch: 676\n",
            "Epoch: 677\n",
            "Epoch: 678\n",
            "Epoch: 679\n",
            "Epoch: 680\n",
            "Epoch: 681\n",
            "Epoch: 682\n",
            "Epoch: 683\n",
            "Epoch: 684\n",
            "Epoch: 685\n",
            "Epoch: 686\n",
            "Epoch: 687\n",
            "Epoch: 688\n",
            "Epoch: 689\n",
            "Epoch: 690\n",
            "Epoch: 691\n",
            "Epoch: 692\n",
            "Epoch: 693\n",
            "Epoch: 694\n",
            "Epoch: 695\n",
            "Epoch: 696\n",
            "Epoch: 697\n",
            "Epoch: 698\n",
            "Epoch: 699\n",
            "Epoch: 700\n",
            "Epoch: 701\n",
            "Epoch: 702\n",
            "Epoch: 703\n",
            "Epoch: 704\n",
            "Epoch: 705\n",
            "Epoch: 706\n",
            "Epoch: 707\n",
            "Epoch: 708\n",
            "Epoch: 709\n",
            "Epoch: 710\n",
            "Epoch: 711\n",
            "Epoch: 712\n",
            "Epoch: 713\n",
            "Epoch: 714\n",
            "Epoch: 715\n",
            "Epoch: 716\n",
            "Epoch: 717\n",
            "Epoch: 718\n",
            "Epoch: 719\n",
            "Epoch: 720\n",
            "Epoch: 721\n",
            "Epoch: 722\n",
            "Epoch: 723\n",
            "Epoch: 724\n",
            "Epoch: 725\n",
            "Epoch: 726\n",
            "Epoch: 727\n",
            "Epoch: 728\n",
            "Epoch: 729\n",
            "Epoch: 730\n",
            "Epoch: 731\n",
            "Epoch: 732\n",
            "Epoch: 733\n",
            "Epoch: 734\n",
            "Epoch: 735\n",
            "Epoch: 736\n",
            "Epoch: 737\n",
            "Epoch: 738\n",
            "Epoch: 739\n",
            "Epoch: 740\n",
            "Epoch: 741\n",
            "Epoch: 742\n",
            "Epoch: 743\n",
            "Epoch: 744\n",
            "Epoch: 745\n",
            "Epoch: 746\n",
            "Epoch: 747\n",
            "Epoch: 748\n",
            "Epoch: 749\n",
            "Epoch: 750\n",
            "Epoch: 751\n",
            "Epoch: 752\n",
            "Epoch: 753\n",
            "Epoch: 754\n",
            "Epoch: 755\n",
            "Epoch: 756\n",
            "Epoch: 757\n",
            "Epoch: 758\n",
            "Epoch: 759\n",
            "Epoch: 760\n",
            "Epoch: 761\n",
            "Epoch: 762\n",
            "Epoch: 763\n",
            "Epoch: 764\n",
            "Epoch: 765\n",
            "Epoch: 766\n",
            "Epoch: 767\n",
            "Epoch: 768\n",
            "Epoch: 769\n",
            "Epoch: 770\n",
            "Epoch: 771\n",
            "Epoch: 772\n",
            "Epoch: 773\n",
            "Epoch: 774\n",
            "Epoch: 775\n",
            "Epoch: 776\n",
            "Epoch: 777\n",
            "Epoch: 778\n",
            "Epoch: 779\n",
            "Epoch: 780\n",
            "Epoch: 781\n",
            "Epoch: 782\n",
            "Epoch: 783\n",
            "Epoch: 784\n",
            "Epoch: 785\n",
            "Epoch: 786\n",
            "Epoch: 787\n",
            "Epoch: 788\n",
            "Epoch: 789\n",
            "Epoch: 790\n",
            "Epoch: 791\n",
            "Epoch: 792\n",
            "Epoch: 793\n",
            "Epoch: 794\n",
            "Epoch: 795\n",
            "Epoch: 796\n",
            "Epoch: 797\n",
            "Epoch: 798\n",
            "Epoch: 799\n",
            "Epoch: 800\n",
            "Epoch: 801\n",
            "Epoch: 802\n",
            "Epoch: 803\n",
            "Epoch: 804\n",
            "Epoch: 805\n",
            "Epoch: 806\n",
            "Epoch: 807\n",
            "Epoch: 808\n",
            "Epoch: 809\n",
            "Epoch: 810\n",
            "Epoch: 811\n",
            "Epoch: 812\n",
            "Epoch: 813\n",
            "Epoch: 814\n",
            "Epoch: 815\n",
            "Epoch: 816\n",
            "Epoch: 817\n",
            "Epoch: 818\n",
            "Epoch: 819\n",
            "Epoch: 820\n",
            "Epoch: 821\n",
            "Epoch: 822\n",
            "Epoch: 823\n",
            "Epoch: 824\n",
            "Epoch: 825\n",
            "Epoch: 826\n",
            "Epoch: 827\n",
            "Epoch: 828\n",
            "Epoch: 829\n",
            "Epoch: 830\n",
            "Epoch: 831\n",
            "Epoch: 832\n",
            "Epoch: 833\n",
            "Epoch: 834\n",
            "Epoch: 835\n",
            "Epoch: 836\n",
            "Epoch: 837\n",
            "Epoch: 838\n",
            "Epoch: 839\n",
            "Epoch: 840\n",
            "Epoch: 841\n",
            "Epoch: 842\n",
            "Epoch: 843\n",
            "Epoch: 844\n",
            "Epoch: 845\n",
            "Epoch: 846\n",
            "Epoch: 847\n",
            "Epoch: 848\n",
            "Epoch: 849\n",
            "Epoch: 850\n",
            "Epoch: 851\n",
            "Epoch: 852\n",
            "Epoch: 853\n",
            "Epoch: 854\n",
            "Epoch: 855\n",
            "Epoch: 856\n",
            "Epoch: 857\n",
            "Epoch: 858\n",
            "Epoch: 859\n",
            "Epoch: 860\n",
            "Epoch: 861\n",
            "Epoch: 862\n",
            "Epoch: 863\n",
            "Epoch: 864\n",
            "Epoch: 865\n",
            "Epoch: 866\n",
            "Epoch: 867\n",
            "Epoch: 868\n",
            "Epoch: 869\n",
            "Epoch: 870\n",
            "Epoch: 871\n",
            "Epoch: 872\n",
            "Epoch: 873\n",
            "Epoch: 874\n",
            "Epoch: 875\n",
            "Epoch: 876\n",
            "Epoch: 877\n",
            "Epoch: 878\n",
            "Epoch: 879\n",
            "Epoch: 880\n",
            "Epoch: 881\n",
            "Epoch: 882\n",
            "Epoch: 883\n",
            "Epoch: 884\n",
            "Epoch: 885\n",
            "Epoch: 886\n",
            "Epoch: 887\n",
            "Epoch: 888\n",
            "Epoch: 889\n",
            "Epoch: 890\n",
            "Epoch: 891\n",
            "Epoch: 892\n",
            "Epoch: 893\n",
            "Epoch: 894\n",
            "Epoch: 895\n",
            "Epoch: 896\n",
            "Epoch: 897\n",
            "Epoch: 898\n",
            "Epoch: 899\n",
            "Epoch: 900\n",
            "Epoch: 901\n",
            "Epoch: 902\n",
            "Epoch: 903\n",
            "Epoch: 904\n",
            "Epoch: 905\n",
            "Epoch: 906\n",
            "Epoch: 907\n",
            "Epoch: 908\n",
            "Epoch: 909\n",
            "Epoch: 910\n",
            "Epoch: 911\n",
            "Epoch: 912\n",
            "Epoch: 913\n",
            "Epoch: 914\n",
            "Epoch: 915\n",
            "Epoch: 916\n",
            "Epoch: 917\n",
            "Epoch: 918\n",
            "Epoch: 919\n",
            "Epoch: 920\n",
            "Epoch: 921\n",
            "Epoch: 922\n",
            "Epoch: 923\n",
            "Epoch: 924\n",
            "Epoch: 925\n",
            "Epoch: 926\n",
            "Epoch: 927\n",
            "Epoch: 928\n",
            "Epoch: 929\n",
            "Epoch: 930\n",
            "Epoch: 931\n",
            "Epoch: 932\n",
            "Epoch: 933\n",
            "Epoch: 934\n",
            "Epoch: 935\n",
            "Epoch: 936\n",
            "Epoch: 937\n",
            "Epoch: 938\n",
            "Epoch: 939\n",
            "Epoch: 940\n",
            "Epoch: 941\n",
            "Epoch: 942\n",
            "Epoch: 943\n",
            "Epoch: 944\n",
            "Epoch: 945\n",
            "Epoch: 946\n",
            "Epoch: 947\n",
            "Epoch: 948\n",
            "Epoch: 949\n",
            "Epoch: 950\n",
            "Epoch: 951\n",
            "Epoch: 952\n",
            "Epoch: 953\n",
            "Epoch: 954\n",
            "Epoch: 955\n",
            "Epoch: 956\n",
            "Epoch: 957\n",
            "Epoch: 958\n",
            "Epoch: 959\n",
            "Epoch: 960\n",
            "Epoch: 961\n",
            "Epoch: 962\n",
            "Epoch: 963\n",
            "Epoch: 964\n",
            "Epoch: 965\n",
            "Epoch: 966\n",
            "Epoch: 967\n",
            "Epoch: 968\n",
            "Epoch: 969\n",
            "Epoch: 970\n",
            "Epoch: 971\n",
            "Epoch: 972\n",
            "Epoch: 973\n",
            "Epoch: 974\n",
            "Epoch: 975\n",
            "Epoch: 976\n",
            "Epoch: 977\n",
            "Epoch: 978\n",
            "Epoch: 979\n",
            "Epoch: 980\n",
            "Epoch: 981\n",
            "Epoch: 982\n",
            "Epoch: 983\n",
            "Epoch: 984\n",
            "Epoch: 985\n",
            "Epoch: 986\n",
            "Epoch: 987\n",
            "Epoch: 988\n",
            "Epoch: 989\n",
            "Epoch: 990\n",
            "Epoch: 991\n",
            "Epoch: 992\n",
            "Epoch: 993\n",
            "Epoch: 994\n",
            "Epoch: 995\n",
            "Epoch: 996\n",
            "Epoch: 997\n",
            "Epoch: 998\n",
            "Epoch: 999\n",
            "Epoch: 1000\n",
            "Epoch: 1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkFmtbsLHM9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}